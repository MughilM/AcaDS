# Academic Data Science Projects
This repository differs from my other Data Science repository in that this one only contains project that I did as part of my academic, including undergraduate and graduate. 

## Graduate Courses
- COMS4995 - Applied Deep Learning
    - **Assignment 1**: Creating and training a linear model on MNIST with no hidden layers. This includes plotting loss and accuracy. We eventually transition to a deep neural network. As a bonus, we use `tf.data` and `GradientTape` to batch the data into a TensorFlow Dataset object instead of using the bulit-in data pipelining in `model.fit`. Lastly, we actually visualize what the learned weights look like in our trained model, and see if there are any patterns present.
    - **Assignment 2**: We build a deep classifier for images of flowers. However, we actually **deploy** this model onto the web using TensorFlow.js, where users can submit images and see predictions in real-time. As a second part to this assignment, we build our own small dataset of landmarks around campus and use transfer learning to achieve a satisfactory accuracy on this small set. This model is also deployed onto the web at [this site](http://mughilm.github.io/COMS4995-ADL/).
    - **Assignment 3**: We learn to utilize some external tools to help us analyze model performance. One is TensorBoard to show training metrics. We showcase this by examining the difference in performance between two activation functions, ReLU and Swish. The swish function was shown to have better consistent performance. Next, we apply the LIME interpretability technique on the Inception image classifier to see which regions of an image contributed to the prediction. Lastly, we show the use of Keras Tuner to tune the hyperparameters of a small model.
    - **Assignment 4**: This notebook contains the implementation of the visual question-answering task, where the model is presented with an image and a short yes/no question, and the model must answer yes/no to the question using the context from the image. The dataset is the COCO 2014 VQA dataset. The first part goes through all of the preprocessing steps. They are shown in the notebook itself, even though the instructions recommend to create a separate one. We use Inception V3 model as a starting point for the images. To model the qusetions, we pad/truncate the questions to 13 words long, and pass them through a basic LSTM network. Along the way, we do multiple sanity checks to make sure our preprocessing steps are working as intended. We also store the activations of the images to disk, so they do not have to be fed through the model again and again.
